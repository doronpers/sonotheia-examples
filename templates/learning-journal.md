# Learning Journal: AI-Assisted Development

Use this template to track your experiences, insights, and lessons learned while working with AI agents in your development workflow.

## Session Information

**Date:** YYYY-MM-DD
**Project:** [Project/Repository name]
**Feature/Task:** [Brief description]
**AI Tools Used:** [e.g., GitHub Copilot, ChatGPT, Claude, etc.]

---

## Problem Definition

**Problem Statement:**
[1-2 sentence description of what you're solving]

**Success Criteria:**
- [ ] [Specific, testable outcome 1]
- [ ] [Specific, testable outcome 2]
- [ ] [Specific, testable outcome 3]

**Constraints:**
- **Performance:** [specific limits]
- **Scale:** [specific limits]
- **Security:** [specific requirements]
- **Infrastructure:** [specific requirements]

---

## AI Interaction Log

### Prompt 1: [Brief description]

**What I asked:**
```
[Your prompt to the AI]
```

**What AI suggested:**
```
[AI's response - can be summary or key points]
```

**What I did:**
- [ ] Accepted as-is
- [ ] Modified (explain below)
- [ ] Rejected (explain below)

**Why:**
[Your reasoning for the decision]

---

### Prompt 2: [Brief description]

**What I asked:**
```
[Your prompt]
```

**What AI suggested:**
```
[AI's response]
```

**What I did:**
- [ ] Accepted as-is
- [ ] Modified (explain below)
- [ ] Rejected (explain below)

**Why:**
[Your reasoning]

---

*(Add more prompts as needed)*

---

## Code Changes

**Files Modified:**
- `path/to/file1.py` - [Brief description of changes]
- `path/to/file2.js` - [Brief description of changes]

**Key Code Snippets:**

```python
# Example: AI suggested this pattern that worked well
def convert_numpy_types(obj):
    if isinstance(obj, np.integer):
        return int(obj)
    # ... etc
```

**Why this worked:**
[Explain what made this solution effective]

---

## Testing Results

**Tests Written:**
- [ ] `test_feature_1` - [What it validates]
- [ ] `test_feature_2` - [What it validates]

**Test Results:**
```bash
# Paste relevant test output
pytest tests/ -v
# 5 passed, 0 failed
```

**Manual Testing:**
- [ ] Tested with [scenario 1]
- [ ] Tested with [scenario 2]
- [ ] Tested edge case: [description]

---

## What Went Well ✅

1. **[Specific thing that worked]**
   - AI suggestion: [what AI suggested]
   - Outcome: [what happened]
   - Why it worked: [your analysis]

2. **[Another success]**
   - AI suggestion: [what AI suggested]
   - Outcome: [what happened]
   - Why it worked: [your analysis]

---

## What Didn't Work ❌

1. **[Specific issue or mistake]**
   - AI suggestion: [what AI suggested]
   - Problem: [what went wrong]
   - Root cause: [your analysis]
   - How I fixed it: [your solution]

2. **[Another issue]**
   - AI suggestion: [what AI suggested]
   - Problem: [what went wrong]
   - Root cause: [your analysis]
   - How I fixed it: [your solution]

---

## Patterns to Remember

### ✅ Patterns That Work

**Pattern:** [Name or brief description]
```python
# Code example
def example_pattern():
    # Implementation
    pass
```
**Use when:** [Specific scenario]
**Why it works:** [Your analysis]

---

### ❌ Patterns to Avoid

**Anti-pattern:** [Name or brief description]
```python
# Code example of what NOT to do
def bad_pattern():
    # Problematic implementation
    pass
```
**Problem:** [Why this doesn't work]
**Instead, use:** [Better approach]

---

## Lessons Learned

### Things AI Got Right
1. [Specific thing] - [Why this was helpful]
2. [Specific thing] - [Why this was helpful]
3. [Specific thing] - [Why this was helpful]

### Things AI Got Wrong
1. [Specific thing] - [What the issue was]
2. [Specific thing] - [What the issue was]
3. [Specific thing] - [What the issue was]

### Things I Need to Always Check
1. [Specific pattern to verify] - [Why it's important]
2. [Specific pattern to verify] - [Why it's important]
3. [Specific pattern to verify] - [Why it's important]

### Better Prompting Strategies
**What didn't work:**
```
[Example of ineffective prompt]
```

**What worked better:**
```
[Example of effective prompt]
```

**Key difference:** [What made it better]

---

## Metrics

### Time Investment
- **Total time:** [X hours]
- **Time with AI:** [X hours]
- **Time fixing AI suggestions:** [X hours]
- **Time testing:** [X hours]

### Code Quality
- **Test coverage:** [X%]
- **Bugs found in review:** [X]
- **Bugs found in testing:** [X]
- **Bugs in production:** [X]

### Efficiency
- **AI suggestions accepted:** [X / Y] ([Z%])
- **AI suggestions modified:** [X / Y] ([Z%])
- **AI suggestions rejected:** [X / Y] ([Z%])

---

## Follow-Up Actions

- [ ] Document this pattern in [location]
- [ ] Update coding standards with [insight]
- [ ] Create reusable helper for [pattern]
- [ ] Add test for [edge case]
- [ ] Review similar code for [issue]

---

## Questions for Next Time

1. [Question about approach/pattern]
2. [Question about AI interaction]
3. [Question about testing/validation]

---

## Related Resources

- Related docs: [link]
- Similar examples: [link]
- Reference material: [link]

---

## Summary

**Overall Experience:**
[1-2 paragraphs summarizing the session]

**Would I use AI again for this type of task?**
[ ] Yes, definitely
[ ] Yes, with modifications
[ ] Maybe, depends on context
[ ] No, better to do manually

**Why:**
[Brief explanation]

**Key Takeaway:**
[One sentence - the most important thing you learned]

---

## Template Metadata

**Template Version:** 1.0
**Last Updated:** 2026-01-04
**Part of:** [AI-Assisted Development Workflow](../.github/QUICK_REFERENCE.md)

---

## Tips for Using This Template

1. **Fill it out during or immediately after** your work session (memories fade!)
2. **Be honest** - capture what didn't work, not just successes
3. **Be specific** - "AI forgot numpy serialization" beats "AI made a mistake"
4. **Track patterns** - look for recurring issues over multiple sessions
5. **Review monthly** - identify trends and adjust your workflow
6. **Share anonymously** - help others learn from your experiences

---
